{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2700,
     "status": "ok",
     "timestamp": 1580846213233,
     "user": {
      "displayName": "Alphonsus Adu-Bredu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCCj6JnvNSfKg4pK67MDw5K5OKX8HNJyYMMRlz8xg=s64",
      "userId": "07447949599962840812"
     },
     "user_tz": 300
    },
    "id": "N7VjCFk-MJw1",
    "outputId": "6f3f0821-34dc-4448-8c1c-8eb0d7c5885d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import torch.utils.data as utils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.optim import lr_scheduler\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1580845442773,
     "user": {
      "displayName": "Alphonsus Adu-Bredu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCCj6JnvNSfKg4pK67MDw5K5OKX8HNJyYMMRlz8xg=s64",
      "userId": "07447949599962840812"
     },
     "user_tz": 300
    },
    "id": "nJPV-keCMR6l",
    "outputId": "319fa963-11b5-48e7-900c-eab92ffff6b9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "003v6vTvgbJf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2294,
     "status": "ok",
     "timestamp": 1580846217828,
     "user": {
      "displayName": "Alphonsus Adu-Bredu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCCj6JnvNSfKg4pK67MDw5K5OKX8HNJyYMMRlz8xg=s64",
      "userId": "07447949599962840812"
     },
     "user_tz": 300
    },
    "id": "W5A4vpubhN1m",
    "outputId": "950fb0b0-b882-48e0-846e-e5836b6fc7dc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3422,
     "status": "ok",
     "timestamp": 1580846221677,
     "user": {
      "displayName": "Alphonsus Adu-Bredu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCCj6JnvNSfKg4pK67MDw5K5OKX8HNJyYMMRlz8xg=s64",
      "userId": "07447949599962840812"
     },
     "user_tz": 300
    },
    "id": "vJGk8V3yu2oI",
    "outputId": "30fca8d4-8313-4584-eff6-9ec377810241"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1f8Tu9TMJxB"
   },
   "outputs": [],
   "source": [
    "class DepressingNet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(DepressingNet, self).__init__()\n",
    "\n",
    "        # Setting up pretrained model\n",
    "        self.model = model\n",
    "\n",
    "        # Defining the fusion layers\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "                                nn.Linear(4,4),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(4,4),\n",
    "                                nn.Linear(4,2))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # forward pass of input 1\n",
    "        output1 = self.model(input1)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.model(input2)\n",
    "        #applying fusion layer\n",
    "        concat = torch.cat((output1, output2),1)\n",
    "#         concat = concat.to('cpu')\n",
    "        res = self.fusion_layer(concat)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5j3jRZtNMJxI"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                img0, img1 , label = data\n",
    "                img0, img1 , label = img0.to(device), img1.to(device) , label.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    res = model(img0, img1)\n",
    "                    res = res.to(device)\n",
    "                    label=label.long()\n",
    "                    label=label.flatten()\n",
    "                    loss = criterion(res, label)\n",
    "                        \n",
    "                    result, preds =torch.max(res, dim=1) \n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() \n",
    "                running_corrects += torch.sum(preds == label.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hVm4A9xMJxP"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7532fm-MJxW"
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYLl5dxIMJxd"
   },
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset():\n",
    "    \n",
    "    def __init__(self,training_csv=None,training_dir=None,transform=None):\n",
    "        # used to prepare the labels and images path\n",
    "        self.training_df=pd.read_csv(training_csv)\n",
    "        self.training_df.dropna(inplace=True)\n",
    "#         self.training_df.columns =[\"image1\",\"image2\",\"label\"]\n",
    "        self.training_dir = training_dir    \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        # getting the image path\n",
    "        image1_path=os.path.join(self.training_dir,str(self.training_df['left_id'].iloc[index])+'.jpg')\n",
    "        image2_path=os.path.join(self.training_dir,str(self.training_df['right_id'].iloc[index])+'.jpg')\n",
    "        \n",
    "        \n",
    "        # Loading the image\n",
    "        img0 = Image.open(image1_path)\n",
    "        img1 = Image.open(image2_path)\n",
    "#         img0 = img0.convert(\"L\")\n",
    "#         img1 = img1.convert(\"L\")\n",
    "        \n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1 , torch.from_numpy(np.array([int(self.training_df['winner'].iloc[index])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qc3ibePEMJxm"
   },
   "outputs": [],
   "source": [
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()\n",
    "\n",
    "class Config():\n",
    "    training_dir = \"/home/bill/urban_planning/images_only/\"\n",
    "    testing_dir =\"/home/bill/urban_planning/images_only/\"\n",
    "    train_batch_size = 32\n",
    "    train_number_epochs = 20\n",
    "\n",
    "training_dir =  \"/home/bill/urban_planning/images_only/\"\n",
    "testing_dir = \"/home/bill/urban_planning/images_only/\"\n",
    "training_dir = \"/home/bill/urban_planning/images_only/\"\n",
    "testing_dir = \"/home/bill/urban_planning/images_only/\"\n",
    "training_csv = \"/home/bill/urban_planning/depressing_train.csv\"\n",
    "testing_csv = \"/home/bill/urban_planning/depressing_test.csv\"\n",
    "home =  \"/home/bill/urban_planning/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWho0Vs9MJxu"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"vgg\"\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "feature_extract = True\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFzV5O15MJx0"
   },
   "outputs": [],
   "source": [
    "siamese_dataset = SiameseNetworkDataset(training_csv,training_dir,\n",
    "                                        transform=transforms.Compose([transforms.Resize((input_size, input_size)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                                                      ])\n",
    "                                       )\n",
    "\n",
    "test_dataset = SiameseNetworkDataset(training_csv=testing_csv,training_dir=testing_dir,\n",
    "                                        transform=transforms.Compose([transforms.Resize((input_size, input_size)),\n",
    "                                        transforms.CenterCrop(input_size),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                                                      ])\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDjb0SKGMJx_"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=Config.train_batch_size)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             num_workers=6,\n",
    "                             batch_size=32,\n",
    "                             shuffle=True)\n",
    "\n",
    "dataloaders_dict={'train':train_dataloader, 'val':test_dataloader}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9926,
     "status": "ok",
     "timestamp": 1580846259206,
     "user": {
      "displayName": "Alphonsus Adu-Bredu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCCj6JnvNSfKg4pK67MDw5K5OKX8HNJyYMMRlz8xg=s64",
      "userId": "07447949599962840812"
     },
     "user_tz": 300
    },
    "id": "rTyRWOC2MJyI",
    "outputId": "24e80a28-b904-4eee-d39a-6ba94fb473b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "model = DepressingNet(model_ft)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "wwOc571CMJyO",
    "outputId": "340d773c-88b6-4a66-b87a-220fccd52728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.0218 Acc: 0.5122\n",
      "val Loss: 0.0216 Acc: 0.5288\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.0215 Acc: 0.5506\n",
      "val Loss: 0.0215 Acc: 0.5596\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.0214 Acc: 0.5692\n",
      "val Loss: 0.0214 Acc: 0.5725\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.5752\n",
      "val Loss: 0.0213 Acc: 0.5784\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.5773\n",
      "val Loss: 0.0213 Acc: 0.5796\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.5808\n",
      "val Loss: 0.0213 Acc: 0.5800\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.5803\n",
      "val Loss: 0.0213 Acc: 0.5804\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.5819\n",
      "val Loss: 0.0213 Acc: 0.5785\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.5811\n",
      "val Loss: 0.0213 Acc: 0.5807\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.5844\n",
      "val Loss: 0.0213 Acc: 0.5806\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.5827\n",
      "val Loss: 0.0213 Acc: 0.5810\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.5817\n",
      "val Loss: 0.0212 Acc: 0.5823\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.5824\n",
      "val Loss: 0.0212 Acc: 0.5807\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.5844\n",
      "val Loss: 0.0212 Acc: 0.5838\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.5851\n",
      "val Loss: 0.0212 Acc: 0.5841\n",
      "Training complete in 136m 20s\n",
      "Best val Acc: 0.584087\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.RMSprop(net.parameters(), lr=1e-4, alpha=0.99, eps=1e-8, weight_decay=0.0005, momentum=0.9)\n",
    "model, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKDksLiJMJyV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"58_4_model.pt\")\n",
    "print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.linspace(1,15,15)\n",
    "y=[]\n",
    "for num in hist:\n",
    "    y.append(num.data.tolist())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x,y)\n",
    "plt.savefig('58_4_training_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train_depressing_net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
